# ğŸ¯ RTX 50ç³»åˆ—æ˜¾å¡æ·±åº¦å­¦ä¹ ç¯å¢ƒ (sm_120æ¶æ„)

## ğŸ“¢ è‡´RTX 50ç³»åˆ—ç”¨æˆ·çš„ç¦éŸ³

å¦‚æœä½ æ­£åœ¨ä¸ºRTX 5080/5090ç­‰50ç³»åˆ—æ˜¾å¡é…ç½®æ·±åº¦å­¦ä¹ ç¯å¢ƒè€Œè‹¦æ¼ï¼Œè¿™ä¸ªä»“åº“å°†å¸®åŠ©ä½ èŠ‚çœå¤§é‡æ—¶é—´ï¼

### ğŸ è¿™ä¸ªç¯å¢ƒè§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ

RTX 50ç³»åˆ—æ˜¾å¡ä½¿ç”¨å…¨æ–°çš„**sm_120æ¶æ„**ï¼Œç›®å‰ä¸»æµPyTorchç¨³å®šç‰ˆè¿˜ä¸æ”¯æŒã€‚å¾ˆå¤šäººé‡åˆ°ï¼š

**ç‰¹åˆ«è¯´æ˜**: åœ¨Ubuntu 22.04ä¸Šé…ç½®RTX 50ç¯å¢ƒç‰¹åˆ«å›°éš¾ï¼Œç»è¿‡æ— æ•°æ¬¡å°è¯•æ‰æˆåŠŸã€‚å‡çº§åˆ°Ubuntu 24.04åï¼Œç¯å¢ƒé…ç½®å˜å¾—å®¹æ˜“å¾ˆå¤šã€‚å¼ºçƒˆå»ºè®®ä½¿ç”¨Ubuntu 24.04ï¼

- âŒ `CUDA error: no kernel image is available for execution on the device`
- âŒ bitsandbytesé‡åŒ–è®­ç»ƒå¤±è´¥
- âŒ PEFT/LoRAè®­ç»ƒæ—¶dtypeè½¬æ¢é”™è¯¯
- âŒ æ¨¡å‹åŠ è½½ææ…¢æˆ–å¤±è´¥
- âŒ è®­ç»ƒé€Ÿåº¦å¼‚å¸¸ç¼“æ…¢

**è¿™ä¸ªç¯å¢ƒå®Œç¾è§£å†³äº†æ‰€æœ‰è¿™äº›é—®é¢˜ï¼**

### âœ… æ”¯æŒçš„æ˜¾å¡

- NVIDIA RTX 5080 (16GB) âœ… å·²æµ‹è¯•
- NVIDIA RTX 5080 Laptop âœ… å·²æµ‹è¯•
- NVIDIA RTX 5090 (ç†è®ºæ”¯æŒ)
- æ‰€æœ‰sm_120æ¶æ„çš„æ˜¾å¡

### ğŸš€ æ ¸å¿ƒç‰¹æ€§

1. **8bité‡åŒ–è®­ç»ƒ** - èŠ‚çœ50%æ˜¾å­˜ï¼Œ16GBæ˜¾å¡å¯è®­ç»ƒ8Bæ¨¡å‹
2. **LoRA/PEFTå¾®è°ƒ** - æ”¯æŒæœ€æ–°çš„å‚æ•°é«˜æ•ˆå¾®è°ƒ
3. **ç¨³å®šè®­ç»ƒé€Ÿåº¦** - 3-4ç§’/æ­¥ï¼ˆbatch_size=2ï¼‰
4. **Qwen/LLaMAæ”¯æŒ** - æ”¯æŒä¸»æµå¤§æ¨¡å‹

### ğŸ“¦ å…³é”®ç»„ä»¶ç‰ˆæœ¬

```python
torch==2.10.0.dev20250921+cu128  # PyTorch nightly (å¿…é¡»!)
transformers==4.56.1
peft==0.17.1
bitsandbytes==0.47.0  # 8bité‡åŒ–
datasets==4.1.1
accelerate==1.10.1
CUDA: 12.8
Python: 3.10.18
```

### ğŸ”§ å¿«é€Ÿå¼€å§‹

#### 1. å…‹éš†ä»“åº“
```bash
git clone https://github.com/tiger965/ttfm-training-env.git
cd ttfm-training-env
```

#### 2. å®‰è£…ç¯å¢ƒ

**æ–¹æ³•A: ä½¿ç”¨conda (æ¨è)**
```bash
# å®‰è£…Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh -b -p ~/miniconda3

# åˆ›å»ºç¯å¢ƒ
source ~/miniconda3/etc/profile.d/conda.sh
conda create -n pytorch python=3.10.18 -y
conda activate pytorch

# å®‰è£…PyTorch nightly (å…³é”®!)
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

**æ–¹æ³•B: ä½¿ç”¨pip**
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv rtx50_env
source rtx50_env/bin/activate

# å®‰è£…PyTorch nightly
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

#### 3. å…³é”®ä¿®å¤ä»£ç 

åœ¨ä½ çš„è®­ç»ƒè„šæœ¬å¼€å¤´æ·»åŠ ï¼š

```python
# RTX 50ç³»åˆ— PEFTä¿®å¤
import peft.tuners.tuners_utils
peft.tuners.tuners_utils.BaseTuner._cast_adapter_dtype = lambda *args, **kwargs: None

# å¦‚æœä½¿ç”¨Qwen3æ¨¡å‹
from transformers.models.auto import configuration_auto, modeling_auto
from transformers.models.qwen2 import Qwen2Config, Qwen2ForCausalLM
configuration_auto.CONFIG_MAPPING._extra_content['qwen3'] = Qwen2Config
modeling_auto.MODEL_FOR_CAUSAL_LM_MAPPING_NAMES['qwen3'] = 'Qwen2ForCausalLM'
```

#### 4. ç¯å¢ƒå˜é‡
```bash
export BNB_CUDA_VERSION=128
export PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True'
```

#### 5. éªŒè¯ç¯å¢ƒ
```bash
python test_environment.py
```

åº”è¯¥çœ‹åˆ°ï¼š
```
âœ… PyTorch: 2.10.0.dev20250921+cu128
âœ… CUDAå¯ç”¨: True
âœ… GPU: NVIDIA GeForce RTX 50xx
âœ… æ˜¾å­˜: xx.xGB
```

### ğŸ“ ç¤ºä¾‹ï¼š8bité‡åŒ–è®­ç»ƒ

```python
from transformers import AutoModelForCausalLM, BitsAndBytesConfig
import torch

# 8bité‡åŒ–é…ç½®
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    bnb_8bit_compute_dtype=torch.float16,
    bnb_8bit_use_double_quant=True,
    bnb_8bit_quant_type="nf8"
)

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "model_name",
    quantization_config=quantization_config,
    device_map="auto",
    torch_dtype=torch.float16
)
```

### âš ï¸ é‡è¦æé†’

1. **å¿…é¡»ä½¿ç”¨PyTorch nightlyç‰ˆæœ¬** - ç¨³å®šç‰ˆä¸æ”¯æŒsm_120
2. **ä¸è¦éšæ„å‡çº§åŒ…** - å¯èƒ½ç ´åå…¼å®¹æ€§
3. **Pythonå¿…é¡»æ˜¯3.10.x** - å…¶ä»–ç‰ˆæœ¬å¯èƒ½æœ‰é—®é¢˜
4. **Windowsç”¨æˆ·** - å»ºè®®ä½¿ç”¨WSL2

### ğŸ› å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆå¿…é¡»ç”¨nightlyç‰ˆæœ¬ï¼Ÿ**
A: RTX 50ç³»åˆ—çš„sm_120æ¶æ„åªåœ¨PyTorch nightlyä¸­æ”¯æŒï¼Œç¨³å®šç‰ˆè¦ç­‰åˆ°2025å¹´ä¸­æ‰ä¼šæ”¯æŒã€‚

**Q: å¯ä»¥ç”¨å…¶ä»–CUDAç‰ˆæœ¬å—ï¼Ÿ**
A: å»ºè®®ä½¿ç”¨CUDA 12.8ï¼Œå…¶ä»–ç‰ˆæœ¬æœªå……åˆ†æµ‹è¯•ã€‚

**Q: è®­ç»ƒé€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ**
A: æ£€æŸ¥batch_sizeæ˜¯å¦ä¸º2ï¼Œå…³é—­tf32ï¼Œä½¿ç”¨fp16_opt_level="O2"ã€‚

**Q: bitsandbytesæŠ¥é”™ï¼Ÿ**
A: ç¡®ä¿è®¾ç½®äº†`export BNB_CUDA_VERSION=128`ã€‚

### ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPRï¼å¦‚æœè¿™ä¸ªç¯å¢ƒå¸®åŠ©äº†ä½ ï¼Œè¯·ç‚¹ä¸ªStar â­

### ğŸ“œ è®¸å¯

MIT License - è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹

### ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰RTX 50ç³»åˆ—æ—©æœŸç”¨æˆ·çš„æµ‹è¯•å’Œåé¦ˆã€‚è¿™ä¸ªç¯å¢ƒæ˜¯åœ¨ç»å†å¤šæ¬¡ç¯å¢ƒå´©æºƒå’Œé‡è£…åæ€»ç»“å‡ºçš„æœ€ä½³å®è·µã€‚

---

**å¦‚æœè¿™ä¸ªä»“åº“å¸®ä½ èŠ‚çœäº†æ—¶é—´ï¼Œè¯·åˆ†äº«ç»™å…¶ä»–RTX 50ç³»åˆ—ç”¨æˆ·ï¼**

æœ€åæ›´æ–°ï¼š2025-09-21
æµ‹è¯•ç¯å¢ƒï¼šUbuntu 24.04 + RTX 5080 16GB + WSL2