#!/bin/bash
# TTFM 24ä»£è®­ç»ƒç³»ç»Ÿå¯åŠ¨è„šæœ¬
# é€‚ç”¨äºUbuntu 24.04 + RTX 5080

echo "================================================"
echo "ğŸš€ TTFM 24ä»£è®­ç»ƒç³»ç»Ÿ - Ubuntu 24.04"
echo "ğŸ“ RTX 5080 8bitè®­ç»ƒç¯å¢ƒ"
echo "================================================"

# æ¿€æ´»condaç¯å¢ƒ
echo "âš™ï¸ æ¿€æ´»PyTorchç¯å¢ƒ..."
source /root/miniconda3/etc/profile.d/conda.sh
conda activate pytorch

# è®¾ç½®ç¯å¢ƒå˜é‡
export BNB_CUDA_VERSION=128
export PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True'
export CUDA_VISIBLE_DEVICES=0

# æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯
echo ""
echo "ğŸ“Š ç¯å¢ƒä¿¡æ¯:"
python -c "import torch; print(f'  PyTorch: {torch.__version__}')"
python -c "import torch; print(f'  CUDA: {torch.cuda.is_available()}')"
python -c "import torch; print(f'  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"}')"
python -c "import bitsandbytes as bnb; print(f'  bitsandbytes: {bnb.__version__}')"

# æ£€æŸ¥è®­ç»ƒçŠ¶æ€
echo ""
echo "ğŸ“ˆ è®­ç»ƒçŠ¶æ€:"
if [ -f "/mnt/d/models/ç•™å­˜æ¨¡å‹/Tigerä¿¡ä»»è®­ç»ƒ/24ä»£ç³»ç»Ÿ/training_state.json" ]; then
    echo "  å‘ç°ä¸Šæ¬¡è®­ç»ƒè®°å½•:"
    cat /mnt/d/models/ç•™å­˜æ¨¡å‹/Tigerä¿¡ä»»è®­ç»ƒ/24ä»£ç³»ç»Ÿ/training_state.json | python -m json.tool
    echo ""
    echo "  å°†ä»æ–­ç‚¹ç»§ç»­è®­ç»ƒ..."
else
    echo "  æ— è®­ç»ƒè®°å½•ï¼Œå°†ä»å¤´å¼€å§‹"
fi

# åˆ‡æ¢åˆ°è„šæœ¬ç›®å½•
cd /home/tiger/tiger_trust_project/scripts

# å¯åŠ¨è®­ç»ƒ
echo ""
echo "ğŸ¯ å¼€å§‹è®­ç»ƒ..."
echo "================================================"
python dierdai_fixed3.py

echo ""
echo "âœ… è®­ç»ƒç»“æŸ"