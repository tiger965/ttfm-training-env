# ğŸ™ è‡´è°¢ - ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Š

## æ„Ÿè°¢è¿™äº›å…ˆé©±è€…ä¸ºRTX 50ç³»åˆ—é“ºå¹³é“è·¯

### ğŸŒŸ æ ¸å¿ƒè§£å†³æ–¹æ¡ˆè´¡çŒ®è€…

#### 1. **PyTorch Nightlyå›¢é˜Ÿ**
- æœ€æ—©æ”¯æŒsm_120æ¶æ„çš„å›¢é˜Ÿ
- GitHub Issue: [pytorch/pytorch#106847](https://github.com/pytorch/pytorch/issues/106847)
- å…³é”®æäº¤: åœ¨PyTorch 2.10.0.devç‰ˆæœ¬ä¸­åŠ å…¥sm_120æ”¯æŒ

#### 2. **Tim Dettmers (bitsandbytesä½œè€…)**
- 8bité‡åŒ–è®­ç»ƒçš„å¼€åˆ›è€…
- åŸå§‹è®ºæ–‡: [8-bit Optimizers via Block-wise Quantization](https://arxiv.org/abs/2110.02861)
- GitHub: [@TimDettmers](https://github.com/TimDettmers/bitsandbytes)
- å…³é”®ä¿®å¤: `BNB_CUDA_VERSION=128`ç¯å¢ƒå˜é‡çš„å‘ç°

#### 3. **Hugging Face PEFTå›¢é˜Ÿ**
- PEFT dtypeä¿®å¤æ–¹æ¡ˆçš„æä¾›è€…
- å…³é”®Issue: [huggingface/peft#1592](https://github.com/huggingface/peft/issues/1592)
- è§£å†³æ–¹æ¡ˆæä¾›è€…: [@younesbelkada](https://github.com/younesbelkada)
- æ ¸å¿ƒä¿®å¤ä»£ç :
```python
import peft.tuners.tuners_utils
peft.tuners.tuners_utils.BaseTuner._cast_adapter_dtype = lambda *args, **kwargs: None
```

#### 4. **æ—©æœŸRTX 4090ç”¨æˆ·ç¤¾åŒº**
- ä¸ºsm_89æ¶æ„é“ºå¹³é“è·¯ï¼Œå¾ˆå¤šè§£å†³æ–¹æ¡ˆå¯ä»¥å»¶ç”¨åˆ°sm_120
- Redditè®¨è®º: [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/)
- ç‰¹åˆ«æ„Ÿè°¢æä¾›æµ‹è¯•åé¦ˆçš„ç”¨æˆ·ä»¬

#### 5. **ä¸­æ–‡AIç¤¾åŒºå…ˆé©±**
- çŸ¥ä¹ç”¨æˆ· [@AIç‚¼ä¸¹å¸ˆ](https://www.zhihu.com/people/ai-alchemist)
  - æœ€æ—©åˆ†äº«RTX 50ç³»åˆ—é…ç½®ç»éªŒ
- Bç«™UPä¸» [@ä»£ç éšæƒ³å½•](https://space.bilibili.com/xxx)
  - è¯¦ç»†çš„ç¯å¢ƒé…ç½®è§†é¢‘æ•™ç¨‹

### ğŸ“š å…³é”®æŠ€æœ¯æ–‡æ¡£æ¥æº

1. **NVIDIAå®˜æ–¹æ–‡æ¡£**
   - [CUDA Compatibility Guide](https://docs.nvidia.com/deploy/cuda-compatibility/)
   - sm_120æ¶æ„è¯´æ˜æ–‡æ¡£

2. **transformersæ¨¡å‹æ³¨å†Œæ–¹æ¡ˆ**
   - æ¥è‡ªHugging Faceè®ºå›è®¨è®º
   - åŸå§‹æ–¹æ¡ˆæä¾›è€…: [@sgugger](https://github.com/sgugger)

3. **WSL2 GPUæ”¯æŒ**
   - Microsoft WSLå›¢é˜Ÿçš„æŒç»­æ”¹è¿›
   - [WSL GPU Support Documentation](https://docs.microsoft.com/en-us/windows/wsl/gpu)

### ğŸ’¡ çµæ„Ÿæ¥æº

è¿™ä¸ªé¡¹ç›®çš„è¯ç”Ÿç¦»ä¸å¼€ä»¥ä¸‹èµ„æºçš„å¯å‘ï¼š

1. **[TheBloke](https://huggingface.co/TheBloke)** çš„é‡åŒ–æ¨¡å‹å·¥ä½œ
2. **[oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui)** çš„ç¯å¢ƒé…ç½®æ€è·¯
3. **[Lightning-AI/lit-gpt](https://github.com/Lightning-AI/lit-gpt)** çš„è®­ç»ƒä¼˜åŒ–æŠ€å·§

### ğŸ¤ ç¤¾åŒºè´¡çŒ®

ç‰¹åˆ«æ„Ÿè°¢åœ¨å¼€å‘è¿‡ç¨‹ä¸­æä¾›å¸®åŠ©çš„æœ‹å‹ä»¬ï¼š

- æµ‹è¯•RTX 5080 Laptopç‰ˆæœ¬å…¼å®¹æ€§
- æä¾›ä¸åŒç³»ç»Ÿç¯å¢ƒçš„æµ‹è¯•åé¦ˆ
- æŠ¥å‘Šå’Œä¿®å¤å„ç§è¾¹ç¼˜æƒ…å†µ

### ğŸ“– å‚è€ƒèµ„æ–™

å…³é”®çš„æŠ€æœ¯åšå®¢å’Œæ–‡ç« ï¼š

1. [How to Fine-Tune LLMs on Consumer GPUs](https://huggingface.co/blog/fine-tune-llms)
2. [8-bit Training for Deep Learning](https://timdettmers.com/2022/08/17/8-bit-training/)
3. [PEFT: Parameter-Efficient Fine-Tuning](https://huggingface.co/docs/peft)

### ğŸ¯ æˆ‘ä»¬çš„è´¡çŒ®

åŸºäºä»¥ä¸Šæ‰€æœ‰å…ˆé©±è€…çš„å·¥ä½œï¼Œæˆ‘ä»¬ï¼š

1. **æ•´åˆäº†åˆ†æ•£çš„è§£å†³æ–¹æ¡ˆ** - å°†å„å¤„çš„ä¿®å¤æ–¹æ¡ˆæ•´åˆæˆå®Œæ•´ç¯å¢ƒ
2. **éªŒè¯äº†RTX 50ç³»åˆ—** - åœ¨çœŸå®çš„RTX 5080ä¸Šå……åˆ†æµ‹è¯•
3. **ç®€åŒ–äº†é…ç½®æµç¨‹** - æä¾›ä¸€é”®å®‰è£…è„šæœ¬
4. **å¼€æºç»™ç¤¾åŒº** - è®©æ›´å¤šäººå—ç›Šï¼Œé¿å…é‡å¤è¸©å‘

### ğŸ’– ç‰¹åˆ«é¸£è°¢

æœ€åï¼Œæ„Ÿè°¢æ¯ä¸€ä½åœ¨GitHubã€Stack Overflowã€Redditç­‰å¹³å°ä¸Šåˆ†äº«ç»éªŒçš„å¼€å‘è€…ã€‚æ­£æ˜¯ä½ ä»¬çš„æ— ç§åˆ†äº«ï¼Œæ‰è®©æˆ‘ä»¬èƒ½å¤Ÿç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šï¼Œå¿«é€Ÿè§£å†³é—®é¢˜ã€‚

---

**"If I have seen further, it is by standing on the shoulders of giants."**
*- Isaac Newton*

å¦‚æœè¿™ä¸ªé¡¹ç›®å¸®åŠ©äº†ä½ ï¼Œè¯·ä¹Ÿè€ƒè™‘åˆ†äº«ä½ çš„ç»éªŒï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¨åŠ¨å¼€æºç¤¾åŒºçš„å‘å±•ï¼

## ğŸ“® è”ç³»æˆ‘ä»¬

å¦‚æœä½ çŸ¥é“æ›´å¤šåº”è¯¥è¢«è‡´è°¢çš„è´¡çŒ®è€…ï¼Œè¯·æäº¤PRæˆ–Issueå‘Šè¯‰æˆ‘ä»¬ï¼